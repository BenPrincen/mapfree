{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956099de-b578-4891-b8d7-621a2c922005",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "\n",
    "HOME = os.environ[\"HOME\"]\n",
    "map_free_path = os.path.join(HOME, \"map_free_localization/mapfree\")\n",
    "\n",
    "if os.path.exists(map_free_path):\n",
    "    sys.path.append(map_free_path)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lib.eval.sift_runner import SiftRunner\n",
    "from lib.eval.mickey_runner import MicKeyRunner\n",
    "from lib.dataset.mapfree import MapFreeDataset\n",
    "from config.default import cfg\n",
    "from lib.camera import Camera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb20a386-848d-4f08-bffd-ad6bd9fe208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../lib/tests/test_data\"\n",
    "config_path = os.path.join(data_dir, \"testset.yaml\")\n",
    "config = cfg\n",
    "config.set_new_allowed(True)\n",
    "config.DEBUG = False\n",
    "\n",
    "# You need to set this up to point at some data on your disk\n",
    "if os.path.exists(config_path):\n",
    "    config.merge_from_file(config_path)\n",
    "    # explicitely setting to None because if loading from yaml it's a string\n",
    "    config.DATASET.SCENES = ['s00001']\n",
    "    config.DATASET.AUGMENTATION_TYPE = None\n",
    "    config.DATASET.DATA_ROOT = '/media/jprincen/HD/Map Free Localization'\n",
    "    config.DATASET.DEPTH_ROOT = '/media/jprincen/HD/Map Free Localization/mickey_depths'\n",
    "else:\n",
    "    config = None\n",
    "dataset = MapFreeDataset(config, \"val\")\n",
    "\n",
    "cl_config_path = \"../config/MicKey/curriculum_learning.yaml\"\n",
    "checkpoint_path = \"../weights/mickey.ckpt\"\n",
    "mickey_runner = MicKeyRunner(cl_config_path, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb75831-06dc-4a4b-b555-05b79fa37546",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "ref_img = data['image0'].numpy()\n",
    "query_img = data['image1'].numpy()\n",
    "camera1 = Camera.from_K(data['K_color0'], data['W'], data['H'])\n",
    "camera2 = Camera.from_K(data['K_color1'], data['W'], data['H'])\n",
    "R, t, num_inliers, ref_pts, query_pts = mickey_runner.run_one(ref_img, query_img, camera1, camera2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe94b1-61f5-4773-92bf-5c60d17e7970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "def plot_images_correspondences(axis, x, y, color, img, title):\n",
    "    axis.imshow(img)\n",
    "    axis.scatter(x, y, color=color, s=1)\n",
    "    axis.set_title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47605c9-bcc9-4996-a20d-35bf57cd4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transform the image from pytorch (C, H, W) to regular format (H, W, C) for display\n",
    "ref_img = (\n",
    "    np.transpose(data[\"image0\"].numpy().squeeze(), (1, 2, 0)) * 255\n",
    ").astype(np.uint8)\n",
    "query_img = (\n",
    "    np.transpose(data[\"image1\"].numpy().squeeze(), (1, 2, 0)) * 255\n",
    ").astype(np.uint8)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "plot_images_correspondences(axes[0], ref_pts[:, 0], ref_pts[:, 1], \"red\", ref_img, \"Reference Image\")\n",
    "plot_images_correspondences(axes[1], query_pts[:, 0], query_pts[:, 1], \"blue\", query_img, \"Query Image\")\n",
    "\n",
    "# Draw lines between them\n",
    "line_sampling = 25\n",
    "for i in range(ref_pts.shape[0]):\n",
    "    if i % line_sampling == 0:\n",
    "        con = matplotlib.patches.ConnectionPatch(xyA=ref_pts[i, :], xyB=query_pts[i, :], coordsA=\"data\", coordsB=\"data\",\n",
    "                                  axesA=axes[0], axesB=axes[1], color=\"green\")\n",
    "        axes[1].add_artist(con)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b1493-0b7f-4265-97cc-6f807d770de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
